---
title: "Data Analysis"
format: revealjs
editor: visual
---

```{r libraries}
library(tidyr)
library(ggplot2)
library(cs84040smo)
library(caret)
library(dplyr)
library(FSelector)
library(pheatmap)
library(corrplot)
library(RColorBrewer)
```

# Importing data

```{r read-data}

BASE_PATH <- file.path("../cs84040/project")
DATA_SAVE_PATH <- file.path(BASE_PATH, "data")

final_labeled_data <- read.csv(file.path(DATA_SAVE_PATH, "final_labeled_data.csv"))
```

## Make target binary and remove unneeded columns

```{r correlation-analysis, message=FALSE}
labeled_data <- final_labeled_data |>
  dplyr::mutate(y = ifelse(Type_Phage == "Virulent", 1, -1),
                .after = Type_Phage) |>
  dplyr::select(-c(X, Meta, Type_Phage))

print(paste("No NAs?", all(!is.na(labeled_data))))

y <- labeled_data |>
    dplyr::select(c(y))
X <- labeled_data |>
    dplyr::select(-c(y))
```
## Exploratory Data Analysis

```{r different-ranges}
X_long <- X[, 1:5] %>%
  tidyr::pivot_longer(tidyr::everything(), names_to = "variable",
                      values_to = "value")

ggplot2::ggplot(X_long, aes(x = variable, y = value, fill = variable)) +
    ggplot2::geom_boxplot() +
    ggplot2::coord_flip() +
    ggplot2::theme_minimal() +
    ggplot2::theme(legend.position = "none") +
    ggplot2::labs(title = "First five features",
                  x = "Feature",
                  y = "Value")
```

```{r summary}
summary(X)[, 1:3]
```

## Preprocessing

We use `caret` and `FSelector` to remove features with near zero variance predictors then select features with a high correlation.

```{r first-steps}
# Remove near zero variance features (reduces to 236 features)
nzv <- caret::nearZeroVar(X, saveMetrics = TRUE)
X_filtered <- X[, !nzv$nzv]

# Find highly correlated features to remove (reduce by 44 features)
high_cor <- caret::findCorrelation(cor(X_filtered), cutoff = 0.95)
X_filtered <- X_filtered[, -high_cor]

# Reduce to 174 by selecting features with higher gain (higher importance)
weights <- FSelector::information.gain(y ~ ., data = cbind(X_filtered, y))
sorted_weights <- sort(weights$attr_importance, decreasing = TRUE)
cumsum_importance <- cumsum(sorted_weights) / sum(sorted_weights)
n_features <- which(cumsum_importance >= 0.95)[1]
```

We select the top `n_features` (= 174) features with the highest information gain.

```{r select-top-features}
top_features <- cutoff.k(weights, k = n_features) # 174
X_selected <- X[, top_features]
```

## Initial PCA

```{r initial-plot}
pca <- prcomp(X_selected, scale. = TRUE)
df_pca <- data.frame(
    PC1 = pca$x[,1],
    PC2 = pca$x[,2],
    class = as.factor(y$y)
)

ggplot(df_pca, aes(x = PC1, y = PC2, color = class)) +
    geom_point(alpha = 0.5) +
    ggtitle("PCA after selecting features") +
    theme_minimal()
```

## Splitting Data

We use caret to split the preprocessed data into training, testing, and validation sets.

```{r splitting-data}

set.seed(107)

in_training <- caret::createDataPartition(y = labeled_data$y, p = .80,
                                          list = FALSE)

X_train <- X_selected[in_training, ]
y_train <- y[in_training, ]

X_test <- X_selected[-in_training, ]
y_test <- y[-in_training, ]
```

# Skewedness, scaling

I suspected the data would be skewed when generating because the peptide frequencies varied and were vary sparse in comparison to biological data generated by BioPython.

```{r skewness}
library(e1071)

skewness_values <- apply(X_train, 2, function(x) {
  skewness(x, na.rm = TRUE)
})
highly_skewed <- abs(skewness_values) > 1
highly_skewed_features <- names(X_train)[highly_skewed]
```

```{r plotting-skewed-data}
X_train[highly_skewed_features[1:6]] |>
    tidyr::pivot_longer(everything()) |>
    ggplot2::ggplot(aes(x = value)) +
    ggplot2::geom_histogram() +
    ggplot2::facet_wrap(~name, scales = "free") +
    ggplot2::theme_minimal()

```

We'll apply a transformation on highly skewed features to reduce the skew with `caret`.

```{r yeo-johnson-then-scale}
# Transform skewed
trans <- caret::preProcess(X_train[, highly_skewed_features],
                           method = c("YeoJohnson"))
X_train_transformed <- X_train
X_train_transformed[, highly_skewed_features] <- predict(trans,
                                                         X_train[, highly_skewed_features])
X_test_transformed <- predict(trans, X_test)

# Scale all
trans2 <- caret::preProcess(X_train_transformed, method = c("center", "scale"))
X_train_transformed <- predict(trans2, X_train_transformed)
X_test_transformed <- predict(trans2, X_test_transformed)

```

## Plotting 2 features after transformation

```{r plotting-transformed-skewed-data}
X_train_transformed[highly_skewed_features[1:6]] |>
    tidyr::pivot_longer(everything()) |>
    ggplot2::ggplot(aes(x = value)) +
    ggplot2::geom_histogram() +
    ggplot2::facet_wrap(~name, scales = "free") +
    theme_minimal()
```

## Downsampling to deal with very biased data

```{r unbalanced}
ys <- table(y)
print(paste("Temperate phage observations are", 100 * ys[1] / sum(ys[2]),
            "% of the data."))
```

To deal with this, we can either downsample or use a package like SMOTE to generate synthetic data. Since there's a lot of positive samples, we'll try downSample with `caret` to reduce the major class.

```{r downsampling}
X_train_down <- caret::downSample(X_train_transformed, factor(y_train))
y_train_balanced <- as.numeric(as.character(X_train_down$Class))
X_train_balanced <- X_train_down[, -ncol(X_train_down)]
y_balanced <- table(y_train_balanced)
print(paste("Temperate phage observations are",
            100 * y_balanced[1] / sum(y_balanced), "% of 720 observations."))
```

## Second PCA

```{r second-plot}
pca <- prcomp(X_train_balanced, scale. = TRUE)
df_pca <- data.frame(
    PC1 = pca$x[,1],
    PC2 = pca$x[,2],
    class = as.factor(y_train_balanced)
)

ggplot(df_pca, aes(x = PC1, y = PC2, color = class)) +
    geom_point(alpha = 0.5) +
    ggtitle("PCA after transformations") +
    theme_minimal()
```
```{r top-50-correlated-featuresheatmap}
cor_matrix <- cor(X_train_balanced)

cor_long <- reshape2::melt(cor_matrix)
cor_long <- cor_long[cor_long$Var1 != cor_long$Var2, ]  # remove diagonal
cor_long <- cor_long[order(abs(cor_long$value), decreasing = TRUE), ]

top_features <- unique(c(as.character(cor_long$Var1[1:50]), 
                         as.character(cor_long$Var2[1:50])))

pheatmap(cor_matrix[top_features, top_features],
         color = colorRampPalette(rev(brewer.pal(n = 7, name = "PuRd")))(100),
         border_color = "white",
         display_numbers = FALSE,
         fontsize = 6,
         main = "Top 50 Correlated Features",
         angle_col = 45)
```
In the top 50 features, there appears to be a negative correlation seem to account
for half of the relationships.

# Prediction

We'll train an SVM implemented with a Sequential Minimal Optimization
algorithm using a gaussian kernel, soft margin, and a max iteration since our
data will likely be hard to train.

```{r training-balanced}
model_balanced <- SmoModel$new(x = X_train_balanced, y = y_train_balanced,
                               kernel = "gaussian", verbose = TRUE, C = 5,
                               sigma = 40.0, tol = 0.001)
fit_smo(model_balanced, max_iterations = 500)
saveRDS(model_balanced,
        file = "~/Classes/cs84040/project/code/cs84040smo/inst/trained_models/balanced_360x360_feat174_training")
#readRDS(model_balanced)
model_balanced

# Training
mb_train_predict <- model_balanced$predict(X_train_balanced)
mb_cm_train  <- confusionMatrix(as.factor(y_train_balanced),
                                as.factor(mb_train_predict),
                                positive = "1")

# Testing
mb_test_predict <- model_balanced$predict(X_test_transformed)
mb_cm_test <- confusionMatrix(factor(y_test), 
                              factor(mb_test_predict),
                              positive = "1")
```

## Confusion Matrix

```{r cm-plot-testing}
# Generated by claude

# Convert to data frame for ggplot
cm_df <- as.data.frame(mb_cm_test$table)
names(cm_df) <- c("Prediction", "Reference", "Count")

# Calculate percentages
cm_df$Percentage <- cm_df$Count / sum(cm_df$Count) * 100

# Add labels for TN, FP, FN, TP
cm_df$Type <- c("TN", "FP", "FN", "TP")

# Add display label
cm_df$Label <- sprintf("%s\n%d\n(%.1f%%)", cm_df$Type, cm_df$Count, cm_df$Percentage)

# Determine if correct or incorrect
cm_df$Correct <- ifelse(cm_df$Prediction == cm_df$Reference, "Correct", "Incorrect")

# Create plot
ggplot(cm_df, aes(x = Reference, y = Prediction, fill = Correct)) +
    geom_tile(color = "white", size = 2) +
    geom_text(aes(label = Label), 
              size = 5,
              fontface = "bold",
              color = "white") +
    scale_fill_manual(values = c("Correct" = "#d88c9a", 
                                  "Incorrect" = "#99c1b9")) +
    labs(
        title = "(Testing) Confusion Matrix",
        subtitle = sprintf(
            "Accuracy: %.1f%% | Balanced Acc: %.1f%%",
            mb_cm_train$overall['Accuracy'] * 100,
            mb_cm_train$byClass['Balanced Accuracy'] * 100
        ),
        x = "Actual Class",
        y = "Predicted Class"
    ) +
    theme_minimal(base_size = 14) +
    theme(
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, size = 11),
        axis.text = element_text(size = 13, face = "bold"),
        legend.position = "bottom",
        legend.title = element_blank()
    ) +
    coord_fixed()
```

```{r testing-for-different-cs}
# Generated by claud

# Test different C values with sigma=40
c_values <- c(0.01, 0.1, 0.5, 1, 5, 10)

for (c_val in c_values) {
    cat(sprintf("\n=== C = %.2f ===\n", c_val))
    model <- SmoModel$new(
        x = X_train_balanced,
        y = y_train_balanced,
        kernel = "gaussian",
        sigma = 40,
        C = c_val,
        tol = 0.001,
        verbose = FALSE
    )
    
    model <- fit_smo(model, max_iterations = 1000)
    
    n_sv <- sum(model$alpha > 1e-8)
    at_C <- sum(abs(model$alpha - model$C) < 1e-8)
    
    preds <- model$predict(X_train_balanced)
    acc <- mean(preds == y_train_balanced)
    
    cat(sprintf("SVs: %3d, At C: %3d, Acc: %.3f, Alpha range: [%.4f, %.4f]\n",
                n_sv, at_C, acc, min(model$alpha), max(model$alpha)))
}
```

```{r auc-roc}
# generated by claude
library(pROC)
library(ggplot2)

# Calculate ROC
roc_obj <- roc(y_test, mb_test_predict)
auc_score <- auc(roc_obj)

# Create data frame
roc_data <- data.frame(
  FPR = 1 - roc_obj$specificities,
  TPR = roc_obj$sensitivities
)

# Plot
ggplot(roc_data, aes(x = FPR, y = TPR)) +
  geom_line(color = "steelblue", size = 1.5) +
  geom_abline(intercept = 0, slope = 1, 
              linetype = "dashed", color = "gray50") +
  theme_minimal() +
  labs(
    title = paste("ROC Curve (AUC =", round(auc_score, 3), ")"),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 11)
  ) +
  coord_fixed(ratio = 1)  # Square plot
```


```{r sessionInfo}
sessionInfo()
```
